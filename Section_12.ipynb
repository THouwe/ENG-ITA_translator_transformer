{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4716656",
   "metadata": {},
   "source": [
    "## Section 12: Improving the Model\n",
    "\n",
    "Letâ€™s go back and review what you did and what can be improved. You made a transformer model that takes an entire English sentence and a partial French sentence (up to the n-th token) to predict the next (the n-th) token.\n",
    "\n",
    "**The accuracy is about 83%.**\n",
    "\n",
    "In the next section, we will trian modified models and compare their performances. Although it is not possible to explore the full 'parameter' space, we will tune one parameter at a time, namely:\n",
    "1. **Tokenization**: Use new tokenizer (e.g., *NLTK*) & sub-tokenizer\n",
    "2. **Word embedding**: Use pre-trained embedding (e.g., *GloVe*)\n",
    "3. **Transformer**: Nr. of multi-head attention heads, sentence length, drop out rate\n",
    "4. **Training**: Nr. of epochs, loss function.\n",
    "\n",
    "Keep your eyes open for the coming improvements!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
