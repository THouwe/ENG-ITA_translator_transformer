{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48c898e5",
   "metadata": {},
   "source": [
    "## Section 2: Data Exploration & Text Normalization\n",
    "\n",
    "Here, we will build a sentence-based English-to-Italian translator. To train the model we will be using the user-contributed data for the flash card app Anki. We will be using the ita.txt file which can be downloaded [here](https://www.manythings.org/anki/) (ita-eng.zip). We then print the first few lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "135b0660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi.\\tCiao!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #607364 (Cero)\\n', 'Hi.\\tCiao.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #4522287 (Guybrush88)\\n', 'Run!\\tCorri!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #906347 (Guybrush88)\\n', 'Run!\\tCorra!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #906348 (Guybrush88)\\n', 'Run!\\tCorrete!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #906350 (Guybrush88)\\n']\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import csv\n",
    "\n",
    "N = 5\n",
    "with open(\"ENG_ITA.txt\") as myfile:\n",
    "    head = [next(myfile) for x in range(N)]\n",
    "print(head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8535000e",
   "metadata": {},
   "source": [
    "Each line is composed by three tab-separated parts:\n",
    "1. English word/sentence (items increase in complexity over the length of the file)\n",
    "2. Italian word/sentence\n",
    "3. copyright.\n",
    "\n",
    "Next, we will create a list of English and Italian item pairs and to perform **tokenization**.\n",
    "\n",
    "\n",
    "### Tokenization.\n",
    "**Tokenization**  is the first step in any NLP pipeline. It has an important effect on the rest of the pipeline. A tokenizer breaks unstructured data and natural language text into chunks of information that can be considered as discrete elements. The token occurrences in a document can be used directly as a vector representing that document. \n",
    "\n",
    "This immediately turns an unstructured string (text document) into a numerical data structure suitable for machine learning. They can also be used directly by a computer to trigger useful actions and responses. Or they might be used in a machine learning pipeline as features that trigger more complex decisions or behavior.\n",
    "\n",
    "Our model will be trained to predict the next word of the target sentence. Therefore, we will perform *word* tokenization (vs, e.g., *sentence* tokenization).\n",
    "\n",
    "We will do this in three ways. We will first use a set of custom-defined functions to normalize and tokenize (i.e., using *str.split()*) (method 1). Next, we will use a pre-trained ML model to tokenize the non-normalized text and re-train the model (method 2). Finally, we will combine the two approaches by tokenizing with the pre-trained model the text already passed through the custom normalization pipeline (method 3). \n",
    "\n",
    "The pre-trained model we will be using comes from the [NLTK]() library. We will call *word_tokenize()*, which uses a sophisticated algorithm to tokenize text into words, called the **Punkt** tokenizer, which is a pre-trained unsupervised machine learning model that was trained on a large corpus of text. It takes into account various linguistic features such as punctuation, capitalization, and contractions to produce more accurate tokenization results.\n",
    "\n",
    "First, we will train the model using the custom tokenization and then after using the more sophisticated tokenization. We will compare the performance of the models.\n",
    "\n",
    "\n",
    "### Normalization.\n",
    "Before tokenization, we will normalize the text using a set of custom functions to:\n",
    "- Normalize the input line of text by applying the \"NFD\" normalization.\n",
    "- Strip any leading and trailing whitespace from the normalized line and make it lowercase.\n",
    "- Use regular expressions to find specific patterns in the text and substitute them with other text. The function applies four substitution operations (e.g., to match any non-whitespace or non-word character at the start of the line and add a space before it). These were defined after data inspection.\n",
    "- Split the line at the tab character, using the split(\"\\t\") method, and assign the resulting parts to three variables, eng, ita and rest.\n",
    "- Wrapping the target (Italian) text with [start] and [end] sentinels. The reason for this will only be clear in Section 11.\n",
    "- expand English contractions (e.g., *he'll* --> *he will*)\n",
    "- remove meaningless accents (English)\n",
    "- substitute meaningful accents (Italian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ee3101ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "\n",
    "def lineSplit(line):\n",
    "    \"\"\"Returns first and second columns of text data (eng and Ita)\"\"\"\n",
    "    p1, p2, p3 = line.split(\"\\t\")  \n",
    "    return p1, p2\n",
    "\n",
    "  \n",
    "def strip_accents(text):\n",
    "    \"\"\"Removes accents. Used for English text only, since accents are meaningless here.\"\"\"\n",
    "    try:\n",
    "        text = unicode(text, 'utf-8')\n",
    "    except NameError: # unicode is a default on python 3 \n",
    "        pass\n",
    "    text = unicodedata.normalize('NFD', text)\\\n",
    "           .encode('ascii', 'ignore')\\\n",
    "           .decode(\"utf-8\")\n",
    "    return str(text)\n",
    "\n",
    "  \n",
    "def substitute_accented(string):\n",
    "    \"\"\"Recodes accents. Used for Italian text only, since accents are meaningful here.\n",
    "    We need to remember to re-code the output of the decoder back to original encoding.\"\"\"\n",
    "    string = re.sub(r'à', 'aa', string)\n",
    "    string = re.sub(r'è', 'ee', string)\n",
    "    string = re.sub(r'ì', 'ii', string)\n",
    "    string = re.sub(r'ò', 'oo', string)\n",
    "    string = re.sub(r'ù', 'uu', string)\n",
    "    string = re.sub(r'á', 'aaa', string)\n",
    "    string = re.sub(r'é', 'eee', string)\n",
    "    string = re.sub(r'í', 'iii', string)\n",
    "    string = re.sub(r'ó', 'ooo', string)\n",
    "    string = re.sub(r'ú', 'uuu', string)  \n",
    "    return string\n",
    "  \n",
    "  \n",
    "  \n",
    "# expand contractions (only applies to English)\n",
    "contractions_dict = {\"ain't\": \"are not\", \"aren't\": \"are not\", \"can't\": \"cannot\", \n",
    "                     \"can't've\": \"cannot have\", \"‘cause\": \"because\", \"could've\": \"could have\", \n",
    "                     \"couldn't\": \"could not\", \"couldn't've\": \"could not have\", \"didn't\": \"did not\", \n",
    "                     \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hadn't've\": \"had not have\", \n",
    "                     \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\", \"he'd've\": \"he would have\", \n",
    "                     \"he'll\": \"he will\", \"he's\": \"he is\",\"he'll've\": \"he will have\", \"how'd\": \"how did\",\n",
    "                     \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"I'd\": \"I would\", \"I'd've\": \"I would have\",\n",
    "                     \"I'll\": \"I will\", \"I'll've\": \"I will have\", \"I'm\": \"I am\", \"I've\": \"I have\", \"isn't\": \"is not\",\n",
    "                     \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\n",
    "                     \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \n",
    "                     \"might've\": \"might have\", \"mightn't\": \"might not\",\n",
    "                     \"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\",\n",
    "                     \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\n",
    "                     \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\",\n",
    "                     \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\",\n",
    "                     \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\",\n",
    "                     \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\n",
    "                     \"so've\": \"so have\", \"that'd\": \"that would\", \"that'd've\": \"that would have\",\n",
    "                     \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"they'd\": \"they would\",\n",
    "                     \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \n",
    "                     \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \n",
    "                     \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\",\n",
    "                     \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\",\"what'll\": \"what will\",\n",
    "                     \"what'll've\": \"what will have\", \"what're\": \"what are\", \"what've\": \"what have\",\n",
    "                     \"when've\": \"when have\", \"where'd\": \"where did\", \"where've\": \"where have\", \"who'll\": \"who will\",\n",
    "                     \"who'll've\": \"who will have\", \"who've\": \"who have\", \"why've\": \"why have\", \"will've\": \"will have\",\n",
    "                     \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\",\n",
    "                     \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                     \"y'all'd've\": \"you all would have\", \"y'all're\": \"you all are\", \"y'all've\": \"you all have\",\n",
    "                     \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\",\n",
    "                     \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "contractions_re = re.compile('(%s)'%'|'.join(contractions_dict.keys()))\n",
    "\n",
    "\n",
    "def expand_contractions(string, contractions_dict=contractions_dict):\n",
    "    \"\"\"Expands English contractions.\"\"\"\n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, string)\n",
    "  \n",
    "  \n",
    "def normalize(line):\n",
    "    \"\"\"Normalizes text by removing/substituting non-ASCII characters,\n",
    "    replaces uppercase with lowercase,\n",
    "    splits into two (Eng, Ita) at the tab character,\n",
    "    adds the [start] and [end] signals\"\"\"\n",
    "    line = line.strip()\n",
    "    line = line.replace(\"’\", \"'\") # both exist, so we replace these before expanding contractions\n",
    "    \n",
    "    line = expand_contractions(line, contractions_dict=contractions_dict)\n",
    "    \n",
    "    line = re.sub(r\"^([^ \\w])(?!\\s)\", r\"\\1 \", line)\n",
    "    line = re.sub(r\"(\\s[^ \\w])(?!\\s)\", r\"\\1 \", line) # will match anything that's not alphanumeric or underscore\n",
    "    line = re.sub(r\"(?!\\s)([^ \\w])$\", r\" \\1\", line)\n",
    "    line = re.sub(r\"(?!\\s)([^ \\w]\\s)\", r\" \\1\", line)\n",
    "    line = re.sub(r\"ñ\", \"n\", line)\n",
    "    line = re.sub(r\"ō\", \"o\", line)\n",
    "    line = re.sub(r\"ê\", \"e\", line)\n",
    "    line = re.sub(r\"ü\", \"u\", line)\n",
    "    line = re.sub(r\"º\", \"o\", line)\n",
    "    line = re.sub(r\"€\", \"Euro\", line)\n",
    "    line = re.sub(r\"°c\", \"oc\", line)\n",
    "    line = re.sub(r\"°\", \" \", line)\n",
    "    line = re.sub(r\"\\xa0\", \" \", line)\n",
    "    line = re.sub(r\"\\u200b\", \"\", line)\n",
    "    line = re.sub(r\"   \", \" \", line)\n",
    "    line = re.sub(r\"  \", \" \", line)\n",
    "    \n",
    "    line = line.lower()\n",
    "    # we run this before and after lowercasing to un-contract first words in the sentence\n",
    "    # which are not in the dictionary because of the first capital letter.\n",
    "    line = expand_contractions(line, contractions_dict=contractions_dict)\n",
    "    \n",
    "    eng, ita, rest = line.split(\"\\t\")\n",
    "    \n",
    "    ita = ita.replace(\"'\", \" \")\n",
    "    ita = substitute_accented(ita)\n",
    "    #ita = re.sub(r'[^\\w]', ' ', ita)\n",
    "    ita = \"[start] \" + ita + \" [end]\"\n",
    "    \n",
    "    eng = strip_accents(eng)\n",
    "    #eng = re.sub(r'[^\\w]', ' ', eng)\n",
    "    \n",
    "    return eng, ita\n",
    "  \n",
    "  \n",
    "def normalize_method2(line):\n",
    "    line = line.strip()\n",
    "    line = line.replace(\"’\", \"'\")\n",
    "    eng, ita, rest = line.split(\"\\t\")\n",
    "    ita = \"[start] \" + ita + \" [end]\"\n",
    "    return eng, ita"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361ed1bc",
   "metadata": {},
   "source": [
    "We now pass the *normalize()* function to our input text and save the pairs of items as a [pickle file](https://docs.python.org/3/library/pickle.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d5997f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file 'ENG_ITA_pairs.pickle' exists in the current directory: not overwriting.\n",
      "file 'ENG_ITA_pairs_method2.pickle' exists in the current directory: not overwriting.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "with open('ENG_ITA.txt', 'r', encoding=\"utf-8\") as fp:  \n",
    "    text_pairs = [normalize(line) for line in fp]\n",
    "\n",
    "file_name = \"ENG_ITA_pairs.pickle\"\n",
    "if os.path.exists(file_name):\n",
    "    print(f\"file '{file_name}' exists in the current directory: not overwriting.\")\n",
    "else:\n",
    "    print(f\"{file_name} does not exist in the current directory: saving.\")    \n",
    "    with open(file_name, \"wb\") as fp:\n",
    "        pickle.dump(text_pairs, fp)\n",
    "    \n",
    "    \n",
    "    \n",
    "with open('ENG_ITA.txt', 'r', encoding=\"utf-8\") as fp:  \n",
    "    text_pairs_method2 = [normalize_method2(line) for line in fp]\n",
    "    \n",
    "file_name = \"ENG_ITA_pairs_method2.pickle\"\n",
    "if os.path.exists(file_name):\n",
    "    print(f\"file '{file_name}' exists in the current directory: not overwriting.\")\n",
    "else:\n",
    "    print(f\"{file_name} does not exist in the current directory: saving.\")    \n",
    "    with open(file_name, \"wb\") as fp:\n",
    "        pickle.dump(text_pairs, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a06a045",
   "metadata": {},
   "source": [
    "Let's now check the differences in encoding between the normalized and non-normalized text pairs. As you can see, the non-normalized text contain many non-ASCII characters. Luckily, *word_tokenize()* can deal with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "eee717c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eng_lines = [line[0] for line in text_pairs]\n",
    "for i in range(0,len(eng_lines)):\n",
    "    this_line = eng_lines[i]\n",
    "    if not this_line.isascii():\n",
    "        print(f\"English line {i} not ASCII: {this_line}\")\n",
    "\n",
    "ita_lines = [line[1] for line in text_pairs]\n",
    "for i in range(0,len(ita_lines)):\n",
    "    this_line = ita_lines[i]\n",
    "    if not this_line.isascii():\n",
    "        print(f\"Italian line {i} not ASCII: {this_line}\")\n",
    "        \n",
    "eng_lines = [line[0] for line in text_pairs_method2]\n",
    "for i in range(0,len(eng_lines)):\n",
    "    this_line = eng_lines[i]\n",
    "    if not this_line.isascii():\n",
    "        print(f\"Method 2: English line {i} not ASCII: {this_line}\")\n",
    "\n",
    "ita_lines = [line[1] for line in text_pairs_method2]\n",
    "for i in range(0,len(ita_lines)):\n",
    "    this_line = ita_lines[i]\n",
    "    if not this_line.isascii():\n",
    "        print(f\"Method 2: Italian line {i} not ASCII: {this_line}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bb9c9b",
   "metadata": {},
   "source": [
    "We then print out a few sentences at random before and after normalization. Beyond, lowercasing and the addition of signals, notice, for instance, how in pair 201979 *I can't* becomes *i cannot* (English), or how in pair 220500, *sarò* becomes *saroo* (Italian) after normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2db94974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence nr. 201979:\n",
      "ENG original: `I can't pretend to like him.` \n",
      "ENG normalized: `i cannot pretend to like him .` \n",
      "ITA original: `Non riesco a fingere che mi piaccia.` \n",
      "ITA normalized: `[start] non riesco a fingere che mi piaccia . [end]` \n",
      "\n",
      "Sentence nr. 220500:\n",
      "ENG original: `I'll never be as rich as Tom.` \n",
      "ENG normalized: `i will never be as rich as tom .` \n",
      "ITA original: `Non sarò mai ricco come Tom.` \n",
      "ITA normalized: `[start] non saroo mai ricco come tom . [end]` \n",
      "\n",
      "Sentence nr. 21225:\n",
      "ENG original: `Let's eat here.` \n",
      "ENG normalized: `let us eat here .` \n",
      "ITA original: `Mangiamo qui.` \n",
      "ITA normalized: `[start] mangiamo qui . [end]` \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "with open('ENG_ITA.txt', 'r', encoding=\"utf8\") as fp:  \n",
    "    tp = [lineSplit(line) for line in fp]   \n",
    "    \n",
    "tp_eng1 = [line[0] for line in tp]\n",
    "tp_eng2 = [line[0] for line in text_pairs]\n",
    "tp_eng3 = [line[0] for line in text_pairs_method2]\n",
    "tp_ita1 = [line[1] for line in tp]\n",
    "tp_ita2 = [line[1] for line in text_pairs]\n",
    "tp_ita3 = [line[1] for line in text_pairs_method2]\n",
    "\n",
    "random.seed(0)\n",
    "for _ in range(3):\n",
    "    i = random.choice(text_pairs)\n",
    "    print(f\"Sentence nr. {text_pairs.index(i)}:\")\n",
    "    print(f\"ENG original: `{tp_eng1[text_pairs.index(i)]}` \")\n",
    "    print(f\"ENG normalized: `{tp_eng2[text_pairs.index(i)]}` \")\n",
    "    print(f\"ITA original: `{tp_ita1[text_pairs.index(i)]}` \")\n",
    "    print(f\"ITA normalized: `{tp_ita2[text_pairs.index(i)]}` \")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d4f2e8",
   "metadata": {},
   "source": [
    "Accents are preserved in the non-normalized text instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e8fdbb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence nr. 201979:\n",
      "ENG normalized method 2: `I can't pretend to like him.` \n",
      "ITA normalized method 2: `[start] Non riesco a fingere che mi piaccia. [end]` \n",
      "\n",
      "Sentence nr. 220500:\n",
      "ENG normalized method 2: `I'll never be as rich as Tom.` \n",
      "ITA normalized method 2: `[start] Non sarò mai ricco come Tom. [end]` \n",
      "\n",
      "Sentence nr. 21225:\n",
      "ENG normalized method 2: `Let's eat here.` \n",
      "ITA normalized method 2: `[start] Mangiamo qui. [end]` \n",
      "\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "for _ in range(3):\n",
    "    i = random.choice(text_pairs_method2)\n",
    "    print(f\"Sentence nr. {text_pairs_method2.index(i)}:\")\n",
    "    print(f\"ENG normalized method 2: `{tp_eng3[text_pairs_method2.index(i)]}` \")\n",
    "    print(f\"ITA normalized method 2: `{tp_ita3[text_pairs_method2.index(i)]}` \")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60aa9202",
   "metadata": {},
   "source": [
    "We now perform 'custom' and ML model-based tokenization on the non-normalized ('NLTK_1') and normalized ('NLTK_2') text.\n",
    "We then print out how many tokens we have and what is the maximum item length.\n",
    "\n",
    "\n",
    "### Optimal number of tokens.\n",
    "There is no definitive answer for the preferred number of tokens for training a transformer model, as it can depend on several factors such as the complexity of the task, the size and quality of the dataset, and the available computational resources. However, some general guidelines state that a smaller number of tokens (e.g., tens of thousands) is preferable if the dataset is small or of lower quality, or if the task is relatively simple. Since we have a rather small dataset, we  prefer a smaller (vs larger) number of tokens.\n",
    "\n",
    "In the end, it is possible that none of this will really matter, after limiting the vocabulary size to less tokens than len(tokens). In fact, we expect this to have limited effect, and we will re-train the model mostly to check this. Next, we will increase vocabulary size by a 20%. We expect this to have, instead, a much larger effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e8e4975e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs: 358373\n",
      "\n",
      "                         | custom | NLTK_1 | NLTK_2 \n",
      "-----------------------------------------------------\n",
      "Total English tokens:    |  14524  |  15633  |  14061\n",
      "Total Italian tokens:    |  27713  |  33149  |  27493\n",
      "Max English item length: |   111   |   111   |   111\n",
      "Max Italian item length: |   103   |   105   |   107\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "eng_tokens, ita_tokens = set(), set()\n",
    "eng_maxlen, ita_maxlen = 0, 0\n",
    "\n",
    "eng_tokens_method2, ita_tokens_method2 = set(), set()\n",
    "eng_maxlen_method2, ita_maxlen_method2 = 0, 0\n",
    "\n",
    "eng_tokens_method3, ita_tokens_method3 = set(), set()\n",
    "eng_maxlen_method3, ita_maxlen_method3 = 0, 0\n",
    "\n",
    "for eng, ita in text_pairs: \n",
    "    eng_tok, ita_tok = eng.split(), ita.split()\n",
    "    eng_maxlen = max(eng_maxlen, len(eng_tok)) # compare maxlen with len of new token\n",
    "    ita_maxlen = max(ita_maxlen, len(ita_tok))\n",
    "    eng_tokens.update(eng_tok) # adds elements if not previously present\n",
    "    ita_tokens.update(ita_tok)\n",
    "    \n",
    "for eng, ita in text_pairs_method2: \n",
    "    eng_tok_method2 = word_tokenize(eng)\n",
    "    ita_tok_method2 = word_tokenize(ita)\n",
    "    eng_maxlen_method2 = max(eng_maxlen_method2, len(eng_tok_method2))\n",
    "    ita_maxlen_method2 = max(ita_maxlen_method2, len(ita_tok_method2))\n",
    "    eng_tokens_method2.update(eng_tok_method2)\n",
    "    ita_tokens_method2.update(ita_tok_method2)\n",
    "    \n",
    "for eng, ita in text_pairs: \n",
    "    eng_tok_method3 = word_tokenize(eng)\n",
    "    ita_tok_method3 = word_tokenize(ita)\n",
    "    eng_maxlen_method3 = max(eng_maxlen_method3, len(eng_tok_method3))\n",
    "    ita_maxlen_method3 = max(ita_maxlen_method3, len(ita_tok_method3))\n",
    "    eng_tokens_method3.update(eng_tok_method3)\n",
    "    ita_tokens_method3.update(ita_tok_method3)\n",
    "\n",
    "print(f\"Total pairs: {len(text_pairs)}\")\n",
    "print(\"\")\n",
    "print(\"                         | custom  |  NLTK_1 | NLTK_2 \")\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(f\"Total English tokens:    |  {len(eng_tokens)}  |  {len(eng_tokens_method2)}  |  {len(eng_tokens_method3)}\")\n",
    "print(f\"Total Italian tokens:    |  {len(ita_tokens)-2}  |  {len(ita_tokens_method2)-2}  |  {len(ita_tokens_method3)-2}\") # -2 for [start] [end]\n",
    "print(f\"Max English item length: |   {eng_maxlen}   |   {eng_maxlen_method2}   |   {eng_maxlen_method3}\")\n",
    "print(f\"Max Italian item length: |   {ita_maxlen-2}   |   {ita_maxlen_method2-2}   |   {ita_maxlen_method3-2}\") # -2 for [start] [end]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fac5e69",
   "metadata": {},
   "source": [
    "The combined normalization + NLTK tokenization seems to have provided the 'best' (less tokens) result. Nevertheless, we are left with quite large numbers of tokens. This is normal since we did not perform stemming or lemmatization.\n",
    "\n",
    "Let's now visualize some of the most uncommon tokens. This is useful to diagnose how effective our text normalization was.\n",
    "There are some entries in English, such as *du* or *meatballs* which will confuse the model (e.g., overfit). The same goes for Italian (e.g., *licenzi* or *videoleso*). We will keep this in mind for later stages.\n",
    "Specifically, when performing *vectorization* (Section 3), we will limit the maximum vocabulary size of the vectorizer, which means that only the most frequent tokens will be considered and encoded. This may be useful to skip the words of little value or with spelling mistakes. We also fix the output length of the vectorizer to 20, since the large majority of sentences have this max len (check figure below; remember log-scaling of y-axis). Thus, output of vectorizer can have no more than 20 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eea1542b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "least common English tokens (N=30):\n",
      "[('adore', 1), ('killed', 1), ('duly', 1), ('frozen', 1), ('temporarily', 1), ('barcelona', 1), ('reckless', 1), ('panther', 1), ('meatballs', 1), ('regard', 1), ('punctured', 1), ('unlike', 1), ('beardless', 1), ('serious', 1), ('sales', 1), ('dentist', 1), ('elegant', 1), ('europeans', 1), ('mistrial', 1), ('discrete', 1), ('discarded', 1), ('greener', 1), ('seize', 1), ('android', 1), ('bids', 1), ('indiscreet', 1), ('pharmacist', 1), ('weighed', 1), ('opposition', 1), ('du', 1)]\n",
      "\n",
      "least common Italian tokens (N=30):\n",
      "[('esitante', 1), ('divampoo', 1), ('licenzi', 1), ('versatili', 1), ('carpe', 1), ('abitassi', 1), ('misericordioso', 1), ('discrete', 1), ('accetta', 1), ('divennero', 1), ('trafficone', 1), ('budapest', 1), ('insostenibile', 1), ('desideriamo', 1), ('videoleso', 1), ('distratto', 1), ('ferme', 1), ('aerei', 1), ('servizio', 1), ('allegro', 1), ('iniziata', 1), ('comincio', 1), ('jeep', 1), ('legato', 1), ('ulteriori', 1), ('rifate', 1), ('rettangolo', 1), ('astiene', 1), ('rugiada', 1), ('bellissimi', 1)]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import collections\n",
    "\n",
    "random.seed(0)\n",
    "counter = collections.Counter(eng_tokens)\n",
    "most_common = counter.most_common()\n",
    "sorted_eng_list = sorted(most_common, key=lambda x: x[1])\n",
    "\n",
    "random.seed(0)\n",
    "counter = collections.Counter(ita_tokens)\n",
    "most_common = counter.most_common()\n",
    "sorted_ita_list = sorted(most_common, key=lambda x: x[1])\n",
    "\n",
    "print(\"Least common English tokens (N=30):\")\n",
    "print(sorted_eng_list[0:30])\n",
    "print(\"\")\n",
    "print(\"Least common Italian tokens (N=30):\")\n",
    "print(sorted_ita_list[0:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba67866",
   "metadata": {},
   "source": [
    "Let's now plot a few statistics about this dataset: let's see how long the items (words, sentences, paragraphs) are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f22cf57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# histogram of sentence length in tokens\n",
    "en_lengths = [len(eng.split()) for eng, ita in text_pairs]\n",
    "it_lengths = [len(ita.split())-2 for eng, ita in text_pairs] # -2 for [start] [end]\n",
    "\n",
    "binwidth = 5\n",
    "\n",
    "plt.hist(en_lengths, \n",
    "         bins=range(1, eng_maxlen + binwidth, binwidth),\n",
    "         label=\"en\", color=\"red\", alpha=0.33)\n",
    "plt.hist(it_lengths,\n",
    "         bins=range(1, eng_maxlen + binwidth, binwidth),\n",
    "         label=\"it\", color=\"blue\", alpha=0.33)\n",
    "plt.yscale(\"log\")     # sentence length fits Benford\"s law\n",
    "plt.ylim(plt.ylim())  # make y-axis consistent for both plots\n",
    "plt.plot([max(en_lengths), max(en_lengths)], plt.ylim(), color=\"red\")\n",
    "plt.plot([max(it_lengths), max(it_lengths)], plt.ylim(), color=\"blue\")\n",
    "plt.xlabel(\"Item Length\")\n",
    "plt.ylabel(\"Cumulative Count\")\n",
    "plt.legend()\n",
    "plt.title(\"Distribution of Item Lengths\")\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(\"section02_figure01_itemLengthDistribution.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91359641",
   "metadata": {},
   "source": [
    "The distribution of token count over item length follows a linear relation in semi-log space in accordance to [Benford's law](https://en.wikipedia.org/wiki/Benford%27s_law). \n",
    "\n",
    "We have now normalized our sentences. In the next section we will be performing vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "78b8b77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK_vocab.pickle does not exist in the current directory: saving.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "file_name = \"NLTK_vocab.pickle\"\n",
    "if os.path.exists(file_name):\n",
    "    print(f\"file '{file_name}' exists in the current directory: not overwriting.\")\n",
    "else:\n",
    "    print(f\"{file_name} does not exist in the current directory: saving.\")    \n",
    "    with open(file_name, \"wb\") as fp:\n",
    "        vocab = {\n",
    "            \"vocab_size_eng\": len(eng_tokens_method3),\n",
    "            \"vocab_size_ita\": len(ita_tokens_method3),\n",
    "            \"vocab_eng\": eng_tokens_method3,\n",
    "            \"vocab_ita\": ita_tokens_method3\n",
    "        }\n",
    "        pickle.dump(vocab, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
